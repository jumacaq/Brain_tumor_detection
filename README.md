# ClasificaciÃ³n de ImÃ¡genes MÃ©dicas con ResNet50 ğŸ§ ğŸ”¬

Este repositorio documenta un proyecto para la clasificaciÃ³n de imÃ¡genes mÃ©dicas, distinguiendo entre imÃ¡genes "Healthy" y con "Tumor". Se utiliza un modelo de Deep Learning basado en la arquitectura ResNet50, implementado con TensorFlow y Keras.  

Las imÃ¡genes utilizadas para el entrenamiento se encuentra en el siguiente repositorio de Kaggle:
https://www.kaggle.com/code/nirmalgaud/brain-tumor-classification-with-fibonaccinet/input

---

## Conceptos relacionados

### La red neuronal convolucional (CNN)
Es un tipo de red neuronal profunda que estÃ¡ diseÃ±ada para procesar eficazmente datos en cuadrÃ­cula o pÃ­xeles, como imÃ¡genes. Consisten en capas de filtros convolucionales que aprenden representaciones jerÃ¡rquicas de las caracterÃ­sticas dentro de los datos de entrada. Las CNN se utilizan ampliamente en tareas como la clasificaciÃ³n, la detecciÃ³n y la segmentaciÃ³n de imÃ¡genes.



### Residual Network (ResNet)
Son un tipo de red neuronal profunda que utiliza **conexiones de salto** (o *skip connections*) para mejorar el aprendizaje en modelos con muchas capas. Estas conexiones permiten que la informaciÃ³n pase directamente entre capas no consecutivas, lo que ayuda a **evitar el problema del gradiente desvanecido**, una dificultad comÃºn en redes profundas donde los gradientes se vuelven muy pequeÃ±os al retropropagarse.

A diferencia de redes tradicionales, donde cada capa solo se conecta con la siguiente, en ResNet **la entrada de un bloque tambiÃ©n se suma a su salida**, creando un atajo que facilita el flujo de informaciÃ³n y mejora la actualizaciÃ³n de los pesos durante el entrenamiento. Esto se implementa frecuentemente usando una funciÃ³n identidad, lo que asegura que el gradiente se conserve sin modificaciones.

Una arquitectura tÃ­pica de ResNet incluye filtros de **convoluciÃ³n 3x3**, capas de **submuestreo** (stride 2), **agrupaciÃ³n promedio global** y una capa final **completamente conectada con softmax**.

ResNet ha demostrado ser muy eficaz en tareas de visiÃ³n por computadora, como clasificaciÃ³n de imÃ¡genes, al permitir construir redes muy profundas sin pÃ©rdida de rendimiento.



### Aprendizaje por Transferencia (Transfer Learning)

El **aprendizaje por transferencia** es una tÃ©cnica de aprendizaje automÃ¡tico que permite **reutilizar el conocimiento aprendido por un modelo en una tarea para resolver otra tarea relacionada**. A diferencia del enfoque tradicional, donde cada modelo se entrena desde cero para tareas especÃ­ficas, el aprendizaje por transferencia parte de un **modelo preentrenado**, lo que **reduce el tiempo de entrenamiento y mejora el rendimiento** cuando los datos disponibles son limitados.

Este enfoque es especialmente Ãºtil cuando los datos de entrenamiento y los datos futuros **no comparten la misma distribuciÃ³n o espacio de caracterÃ­sticas**, algo comÃºn en problemas del mundo real. Por ejemplo, podrÃ­amos tener muchos datos en un dominio (fuente) y pocos en otro (destino), pero si las tareas estÃ¡n relacionadas, **transferir el conocimiento puede ser muy eficaz**.

Los humanos usamos este principio de forma natural: aplicamos conocimientos previos para resolver nuevos problemas similares. El aprendizaje por transferencia lleva esta capacidad al campo de las mÃ¡quinas, **rompiendo el paradigma del aprendizaje aislado**.

Cuanto **mÃ¡s similares sean las tareas**, mÃ¡s efectiva serÃ¡ la transferencia. Es una herramienta clave en Ã¡reas como visiÃ³n por computadora, procesamiento del lenguaje natural y mÃ¡s.

![Transfer Learning](Images/transfer_learn.png)

---


## ğŸš€ Estructura del Proyecto 

La estructura del proyecto es la siguiente:

```bash
Brain_tumor_detection/
â”‚
â”œâ”€â”€ app.py                     # App de Streamlit
â”œâ”€â”€ requirements.txt           # Dependencias del proyecto
â”œâ”€â”€ README.md                  # DescripciÃ³n general
â”‚
â”œâ”€â”€ model/
â”‚   â””â”€â”€ final_resnet_model.h5 # Modelo entrenado (vÃ­a Git LFS)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ tumor_detection_pipeline.ipynb  # Notebook de desarrollo / entrenamiento
â”‚
â”œâ”€â”€ Images/
â”‚   â”œâ”€â”€ confussion_matrix.png
â”‚   â”œâ”€â”€ training_history.png
â”‚   â””â”€â”€ transfer_learn.png    # Usadas en README.md
â”‚
â””â”€â”€ .gitattributes             # Git LFS configurado para .h5
```

El proyecto se organiza en cuatro bloques funcionales principales:

### Bloque 1: **ConfiguraciÃ³n Inicial y Carga de Datos** ğŸ“‚
Esta fase establece el entorno bÃ¡sico y carga el conjunto de datos de imÃ¡genes.
- Se preparan las herramientas necesarias, siendo **TensorFlow** el framework principal para el modelado.
- Como datos tenemos 5000 imÃ¡genes de resonancia magnÃ©tica que se cargan desde un sistema de archivos estructurado, donde las rutas y sus correspondientes etiquetas (ej. "Healthy" con 2000 imÃ¡genes , "Tumor" con 3000 imÃ¡genes) se organizan en un formato manejable, tÃ­picamente un DataFrame de Pandas.

### Bloque 2: **Preprocesamiento y Generadores de ImÃ¡genes** ğŸ–¼ï¸â¡ï¸ğŸ”¢
Antes del entrenamiento, los datos de imÃ¡genes requieren una preparaciÃ³n significativa:
- **CodificaciÃ³n de Etiquetas**: Las etiquetas textuales de las clases se convierten a un formato numÃ©rico.
- **DivisiÃ³n de Datos**: El dataset se divide en conjuntos de entrenamiento (80%), validaciÃ³n(10%) y prueba(10%).
- **Generadores de Datos (`ImageDataGenerator`)**: Se configuran generadores para alimentar eficientemente al modelo:
    - Para el entrenamiento, se aplica **aumentaciÃ³n de datos** (rotaciones, zoom, etc.) y el preprocesamiento especÃ­fico de ResNet.
    - Para validaciÃ³n y prueba, solo se aplica el preprocesamiento de ResNet, sin aumentaciÃ³n, para una evaluaciÃ³n objetiva.

### Bloque 3: **ConstrucciÃ³n y Entrenamiento del Modelo ResNet50** ğŸ§ ğŸ”§
AquÃ­ se define la arquitectura del modelo de Transfer Learning y se lleva a cabo el proceso de entrenamiento:
- **Modelo Base ResNet50**: Se carga la arquitectura ResNet50 pre-entrenada, sin su capa clasificadora original.
- **Capas Personalizadas**: Se aÃ±aden capas superiores (ej. GlobalAveragePooling, Dropout, Dense con activaciÃ³n sigmoide) para adaptar el modelo a la tarea de clasificaciÃ³n binaria.
- **Entrenamiento en Dos Fases**:
    1.  **Entrenamiento del Clasificador**: Inicialmente, solo se entrenan las capas personalizadas nuevas, manteniendo congelado el modelo base ResNet50. Se establece la ejecuciÃ³n de 10   epocas en esta primera fase, obteniendose estos resultados:
       
       accuracy: 0.9484 - auc: 0.9888 - loss: 0.1678 - val_accuracy: 0.9520 - val_auc: 0.9937 - val_loss: 0.1444 - learning_rate: 0.0010
    3.  **Fine-Tuning**: Posteriormente, se descongela el modelo base ResNet50 (o parte de Ã©l) y se continÃºa el entrenamiento de todo el modelo con una tasa de aprendizaje mÃ¡s baja para un ajuste fino. Se agregan 10 Ã©pocas adicionales para el fine-tuning, obteniendo una mejora en los resultados:

       accuracy: 0.9973 - auc: 1.0000 - loss: 0.0392 - val_accuracy: 0.9960 - val_auc: 0.9999 - val_loss: 0.0395 - learning_rate: 1.0000e-05
- **Callbacks**: Se utilizan `EarlyStopping`, `ModelCheckpoint` y `ReduceLROnPlateau` para gestionar el entrenamiento, guardar el mejor modelo y ajustar la tasa de aprendizaje dinÃ¡micamente.

### Bloque 4: **EvaluaciÃ³n del Modelo y VisualizaciÃ³n de Resultados** ğŸ“ŠğŸ“ˆ
Finalmente, se evalÃºa el rendimiento del modelo entrenado utilizando el conjunto de prueba:

- **Matriz de ConfusiÃ³n**.

  Realizada sobre la base de test, muestra una precisiÃ³n del 99%
  
     ![confussion_matrix](Images/confussion_matrix.png)

- **Reporte de ClasificaciÃ³n** (precisiÃ³n, recall, F1-score).
 
  ### ğŸ“Š Reporte de ClasificaciÃ³n

```
                          precision    recall  f1-score   support

              Healthy       0.99      0.99      0.99       200
                Tumor       0.99      1.00      1.00       300
              accuracy                           0.99       500
             macro avg       0.99      0.99      0.99       500
          weighted avg       0.99      0.99      0.99       500
```
 

- **Curva ROC**.
  
  ![roc_curve](Images/roc_curve.png)
  
- Se grafica el **historial de entrenamiento** (pÃ©rdida y exactitud a lo largo de las Ã©pocas) para analizar el proceso de aprendizaje.
  
   ![training_history](Images/training_history.png)
  

## ğŸ› ï¸ Despliegue en streamlit

- Se ejecuta un MVP desplegado en la plataforma Streamlit para probar el modelo con imagenes nuevas

 https://braintumordetection-1.streamlit.app/



## ğŸ”¬ TecnologÃ­as Clave

*   **Python**
*   **TensorFlow / Keras**
*   **ResNet50 (Transfer Learning)**
*   **Pandas, NumPy, Scikit-learn, Matplotlib**
